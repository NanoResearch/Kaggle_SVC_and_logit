{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import joblib\n",
      "from sklearn import preprocessing\n",
      "from sklearn import linear_model\n",
      "from sklearn import svm "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The purpose of this notebook is to select features and to utilize two models in order to:\n",
      "\n",
      "1. Predict probability of loan deafult\n",
      "2. Predict the Loss Given Default (percentage of loss over the total exposure when bank's counterparty defaults)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load training and test data:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Rudimentary data imputation:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load the data utilizing Pandas' .csv reader as it is significantly faster than NumPy's costly (due to intermediate python object steps) loadtxt. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = pd.read_table('train_v2.csv', sep=',', warn_bad_lines=True, error_bad_lines=True) \n",
      "X = np.asarray(X.values, dtype = np.float)\n",
      "\n",
      "imp = preprocessing.Imputer(strategy='most_frequent', axis=0) # strategy='most_frequent'\n",
      "X = imp.fit_transform(X)\n",
      "\n",
      "labels = np.asarray(X[:,-1], dtype = np.float)\n",
      "trainData = np.asarray(X[:,1:-4], dtype = np.float)\n",
      "trainData = preprocessing.scale(trainData)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = pd.read_table('test_v2.csv', sep=',', warn_bad_lines=True, error_bad_lines=True)\n",
      "X = np.asarray(X.values, dtype = np.float) # will not make copy by default\n",
      "\n",
      "imp = preprocessing.Imputer(strategy='most_frequent', axis=0) # strategy='most_frequent'\n",
      "X = imp.fit_transform(X)\n",
      "\n",
      "testData = np.asarray(X[:,1:-3], dtype = np.float)\n",
      "testData = preprocessing.scale(testData)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Predict Default (classification):"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since the first step is to simply predict default, we will convert the detailed float labels (y) to binary integers then train a Support Vector Machine classifier to select features for a later logistic regression model. \n",
      "\n",
      "The SVM performs classification via construction of hyperplanes in multidimensional space that separates instances of different class labels. SVM supports both regression and classification tasks and can handle multiple continuous and categorical variables. For categorical variables a dummy variable is created with case values as either 0 or 1. Thus, a categorical dependent variable consisting of three levels, say (A, B, C), is represented by a set of three dummy variables:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels = np.asarray(labels.astype(int))\n",
      "#labels = np.asarray(map(int,labels))\n",
      "\n",
      "binary_labels = np.asarray([1 if i > 0 else 0 for i in labels]) # Convert int to boolean int.\n",
      "\n",
      "lsvc = svm.LinearSVC(C=0.01, penalty=\"l1\", dual=False, verbose = 2) \n",
      "lsvc.fit(trainData, binary_labels) # Fit the model according to the given training data.\n",
      "\n",
      "pred_trainData = lsvc.transform(trainData) # Reduce train_data to its most important features.\n",
      "pred_testData =  lsvc.transform(testData)  # Reduce ttest_data to its most important features."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels.shape, binary_labels.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "((105471,), (105471,))"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Predict LGD (regression):"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Records pertaining to a default are used for the next step of processing via Logistic Regression (logit) with L1 and L2 regulariziation utilizing full original feature set. Non-defaulting records are assigneda  prediction of value of zero."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zeros_test_len = np.asarray([0] * testData.shape[0])\n",
      "\n",
      "\n",
      "clf = linear_model.LogisticRegression(penalty='l2', dual=True, tol=0.0001, C=1.0, fit_intercept=True,\n",
      "                                      intercept_scaling=1.0, class_weight=None, random_state=None)\n",
      "\n",
      "clf.fit(pred_trainData, binary_labels)\n",
      "test_clf_predict = clf.predict(pred_testData)\n",
      "\n",
      "clftrain = np.where(binary_labels > 0)[0]\n",
      "clftest = np.where(test_clf_predict == 1)[0]\n",
      "\n",
      "clftrain0 = np.where(binary_labels == 0)[0]\n",
      "clftest0 = np.where(test_clf_predict == 0)[0]\n",
      "\n",
      "pred_trainData = trainData[clftrain]\n",
      "pred_testData = testData[clftest]\n",
      "\n",
      "train_labels0 = labels[clftrain0]\n",
      "train_labels1 = labels[clftrain]\n",
      "\n",
      "clf.fit(pred_trainData,train_labels1)\n",
      "preds = clf.predict(pred_testData)\n",
      "\n",
      "zeros_test_len[clftest] = preds\n",
      "zeros_test_len[clftest0] = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save predictions as csv:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ids = np.arange(105472,316416)\n",
      "labels_and_pred = np.vstack((ids,zeros_test_len)).T\n",
      "np.savetxt('predictions4.csv',labels_and_pred ,delimiter = ',',header= \"id,loss\", fmt = '%d', comments='')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "For Main:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The joblib library is significantly faster with large numpy arrays because it has a special handling for the array buffers of the numpy datastructure. It can also compress that data on the fly while pickling using zlib.\n",
      "\n",
      "Joblib also makes it possible to memory map the data buffer of a uncompressed joblib-pickled numpy array when loading it which makes it possible to share memory between processes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# def load_train_data(fname):"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# def load_test_data(fname):\n",
      "#     return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# def predict_labels(clf, trainData, labels, testData):\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# if __name__ == '__main__':\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    }
   ],
   "metadata": {}
  }
 ]
}